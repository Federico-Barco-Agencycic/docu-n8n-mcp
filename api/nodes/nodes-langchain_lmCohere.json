{
  "node_type": "nodes-langchain.lmCohere",
  "display_name": "Cohere Model",
  "description": "Language Model Cohere",
  "category": "transform",
  "development_style": "programmatic",
  "package_name": "@n8n/n8n-nodes-langchain",
  "version": "1",
  "is_ai_tool": true,
  "is_trigger": false,
  "is_webhook": false,
  "is_versioned": false,
  "has_documentation": true,
  "documentation": "---\n#https://www.notion.so/n8n/Frontmatter-432c2b8dff1f43d4b1c8d20075510fe4\ntitle: Cohere Model node documentation\ndescription: Learn how to use the Cohere Model node in n8n. Follow technical documentation to integrate Cohere Model node into your workflows.\ncontentType: [integration, reference]\n---\n\n# Cohere Model node\n\nUse the Cohere Model node to use Cohere's models.\n\nOn this page, you'll find the node parameters for the Cohere Model node, and links to more resources.\n\nThis node lacks tools support, so it won't work with the [AI Agent](/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.agent/index.md) node. Instead, connect it with the [Basic LLM Chain](/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.chainllm.md) node.\n\n/// note | Credentials\nYou can find authentication information for this node [here](/integrations/builtin/credentials/cohere.md).\n///\n\n--8<-- \"_snippets/integrations/builtin/cluster-nodes/sub-node-expression-resolution.md\"\n\n## Node Options\n\n* **Maximum Number of Tokens**: Enter the maximum number of tokens used, which sets the completion length.\n* **Sampling Temperature**: Use this option to control the randomness of the sampling process. A higher temperature creates more diverse sampling, but increases the risk of hallucinations.\n\n## Templates and examples\n\n<!-- see https://www.notion.so/n8n/Pull-in-templates-for-the-integrations-pages-37c716837b804d30a33b47475f6e3780 -->\n[[ templatesWidget(page.title, 'cohere-model') ]]\n\n## Related resources\n\nRefer to [LangChains's Cohere documentation](https://js.langchain.com/docs/integrations/llms/cohere/){:target=_blank .external-link} for more information about the service.\n\n--8<-- \"_snippets/integrations/builtin/cluster-nodes/langchain-overview-link.md\"\n--8<-- \"_glossary/ai-glossary.md\"\n",
  "properties_schema": [
    {
      "displayName": "This node must be connected to an AI chain. <a data-action='openSelectiveNodeCreator' data-action-parameter-creatorview='AI'>Insert one</a>",
      "name": "notice",
      "type": "notice",
      "default": "",
      "typeOptions": {
        "containerClass": "ndv-connection-hint-notice"
      }
    },
    {
      "displayName": "Options",
      "name": "options",
      "type": "collection",
      "default": {},
      "description": "Additional options to add",
      "options": [
        {
          "displayName": "Maximum Number of Tokens",
          "name": "maxTokens",
          "default": 250,
          "description": "The maximum number of tokens to generate in the completion. Most models have a context length of 2048 tokens (except for the newest models, which support 32,768).",
          "type": "number",
          "typeOptions": {
            "maxValue": 32768
          }
        },
        {
          "displayName": "Model",
          "name": "model",
          "type": "string",
          "description": "The name of the model to use",
          "default": ""
        },
        {
          "displayName": "Sampling Temperature",
          "name": "temperature",
          "default": 0,
          "typeOptions": {
            "maxValue": 1,
            "minValue": 0,
            "numberPrecision": 1
          },
          "description": "Controls randomness: Lowering results in less random completions. As the temperature approaches zero, the model will become deterministic and repetitive.",
          "type": "number"
        }
      ]
    }
  ],
  "operations": [],
  "credentials_required": [
    {
      "name": "cohereApi",
      "required": true
    }
  ],
  "generated_at": "2025-07-23T02:24:22.266Z",
  "api_version": "1.0.0"
}