{
  "node_type": "nodes-langchain.chainLlm",
  "display_name": "Basic LLM Chain",
  "description": "A simple chain to prompt a large language model",
  "category": "transform",
  "development_style": "programmatic",
  "package_name": "@n8n/n8n-nodes-langchain",
  "version": "1.7",
  "is_ai_tool": true,
  "is_trigger": false,
  "is_webhook": false,
  "is_versioned": true,
  "has_documentation": true,
  "documentation": "---\n#https://www.notion.so/n8n/Frontmatter-432c2b8dff1f43d4b1c8d20075510fe4\ntitle: Basic LLM Chain node documentation\ndescription: Learn how to use the Basic LLM Chain node in n8n. Follow technical documentation to integrate Basic LLM Chain node into your workflows.\ncontentType: [integration, reference]\npriority: critical\n---\n\n# Basic LLM Chain node\n\nUse the Basic LLM Chain node to set the prompt that the model will use along with setting an optional parser for the response.\n\nOn this page, you'll find the node parameters for the Basic LLM Chain node and links to more resources.\n\n/// note | Examples and templates\nFor usage examples and templates to help you get started, refer to n8n's [Basic LLM Chain integrations](https://n8n.io/integrations/basic-llm-chain/){:target=_blank .external-link} page.\n///\t\n\n## Node parameters\n\n### Prompt\n\n--8<-- \"_snippets/integrations/builtin/cluster-nodes/langchain-root-nodes/prompt.md\"\n\n### Require Specific Output Format\n\n--8<-- \"_snippets/integrations/builtin/cluster-nodes/langchain-root-nodes/output-format.md\"\n\n## Chat Messages\n\nUse **Chat Messages** when you're using a chat model to set a message.\n\nn8n ignores these options if you don't connect a chat model. Select the **Type Name or ID** you want the node to use:\n\n#### AI\n\nEnter a sample expected response in the **Message** field. The model will try to respond in the same way in its messages.\n\n#### System\n\nEnter a system **Message** to include with the user input to help guide the model in what it should do.\n\nUse this option for things like defining tone, for example: `Always respond talking like a pirate`.\n\n#### User\n\nEnter a sample user input. Using this with the AI option can help improve the output of the agent. Using both together provides a sample of an input and expected response (the **AI Message**) for the model to follow.\n\nSelect one of these input types:\n\n* **Text**: Enter a sample user input as a text **Message**.\n* **Image (Binary)**: Select a binary input from a previous node. Enter the **Image Data Field Name** to identify which binary field from the previous node contains the image data.\n* **Image (URL)**: Use this option to feed an image in from a URL. Enter the **Image URL**.\n\nFor both the **Image** types, select the **Image Details** to control how the model processes the image and generates its textual understanding. Choose from:\n\n* **Auto**: The model uses the auto setting, which looks at the image input size and decide if it should use the Low or High setting.\n* **Low**: The model receives a low-resolution 512px x 512px version of the image and represents the image with a budget of 65 tokens. This allows the API to return faster responses and consume fewer input tokens. Use this option for use cases that don't require high detail.\n* **High**: The model can access the low-resolution image and then creates detailed crops of input images as 512px squares based on the input image size. Each of the detailed crops uses twice the token budget (65 tokens) for a total of 129 tokens. Use this option for use cases that require high detail.\n\n## Templates and examples\n\n<!-- see https://www.notion.so/n8n/Pull-in-templates-for-the-integrations-pages-37c716837b804d30a33b47475f6e3780 -->\n[[ templatesWidget(page.title, 'basic-llm-chain') ]]\n\n## Related resources\n\nRefer to [LangChain's documentation on Basic LLM Chains](https://js.langchain.com/docs/tutorials/llm_chain/){:target=_blank .external-link} for more information about the service.\n\n--8<-- \"_snippets/integrations/builtin/cluster-nodes/langchain-overview-link.md\"\n--8<-- \"_glossary/ai-glossary.md\"\n\n## Common issues\n\nHere are some common errors and issues with the Basic LLM Chain node and steps to resolve or troubleshoot them.\n\n### No prompt specified error\n\nThis error displays when the **Prompt** is empty or invalid.\n\nYou might see this error in one of two scenarios:\n\n1. When you've set the **Prompt** to **Define below** and haven't entered anything in the **Text** field.\n    * To resolve, enter a valid prompt in the **Text** field.\n2. When you've set the **Prompt** to **Connected Chat Trigger Node** and the incoming data has no field called `chatInput`. \n    * The node expects the `chatInput` field. If your previous node doesn't have this field, add an [Edit Fields (Set)](/integrations/builtin/core-nodes/n8n-nodes-base.set.md) node to edit an incoming field name to `chatInput`.\n",
  "properties_schema": [
    {
      "displayName": "Save time with an <a href=\"/templates/1978\" target=\"_blank\">example</a> of how this node works",
      "name": "notice",
      "type": "notice",
      "default": ""
    },
    {
      "displayName": "Prompt",
      "name": "prompt",
      "type": "string",
      "default": "={{ $json.input }}",
      "required": true,
      "displayOptions": {
        "show": {
          "@version": [
            1
          ]
        }
      }
    },
    {
      "displayName": "Prompt",
      "name": "prompt",
      "type": "string",
      "default": "={{ $json.chat_input }}",
      "required": true,
      "displayOptions": {
        "show": {
          "@version": [
            1.1,
            1.2
          ]
        }
      }
    },
    {
      "displayName": "Prompt",
      "name": "prompt",
      "type": "string",
      "default": "={{ $json.chatInput }}",
      "required": true,
      "displayOptions": {
        "show": {
          "@version": [
            1.3
          ]
        }
      }
    },
    {
      "displayName": "Source for Prompt (User Message)",
      "name": "promptType",
      "type": "options",
      "default": "auto",
      "options": [
        {
          "name": "Connected Chat Trigger Node",
          "value": "auto",
          "description": "Looks for an input field called 'chatInput' that is coming from a directly connected Chat Trigger"
        },
        {
          "name": "Define below",
          "value": "define",
          "description": "Use an expression to reference data in previous nodes or enter static text"
        }
      ],
      "displayOptions": {
        "hide": {
          "@version": [
            1,
            1.1,
            1.2,
            1.3
          ]
        }
      }
    },
    {
      "displayName": "Prompt (User Message)",
      "name": "text",
      "type": "string",
      "default": "={{ $json.chatInput }}",
      "required": true,
      "displayOptions": {
        "show": {
          "promptType": [
            "auto"
          ],
          "@version": [
            {
              "_cnd": {
                "gte": 1.5
              }
            }
          ]
        }
      },
      "typeOptions": {
        "rows": 2
      }
    },
    {
      "displayName": "Prompt (User Message)",
      "name": "text",
      "type": "string",
      "default": "",
      "required": true,
      "displayOptions": {
        "show": {
          "promptType": [
            "define"
          ]
        }
      },
      "typeOptions": {
        "rows": 2
      }
    },
    {
      "displayName": "Require Specific Output Format",
      "name": "hasOutputParser",
      "type": "boolean",
      "default": false,
      "displayOptions": {
        "hide": {
          "@version": [
            1,
            1.1,
            1.3
          ]
        }
      },
      "noDataExpression": true
    },
    {
      "displayName": "Chat Messages (if Using a Chat Model)",
      "name": "messages",
      "type": "fixedCollection",
      "default": {},
      "options": [
        {
          "name": "messageValues",
          "displayName": "Prompt",
          "values": [
            {
              "displayName": "Type Name or ID",
              "name": "type",
              "type": "options",
              "options": [
                {
                  "name": "AI",
                  "value": "AIMessagePromptTemplate"
                },
                {
                  "name": "System",
                  "value": "SystemMessagePromptTemplate"
                },
                {
                  "name": "User",
                  "value": "HumanMessagePromptTemplate"
                }
              ],
              "default": "SystemMessagePromptTemplate"
            },
            {
              "displayName": "Message Type",
              "name": "messageType",
              "type": "options",
              "displayOptions": {
                "show": {
                  "type": [
                    "HumanMessagePromptTemplate"
                  ]
                }
              },
              "options": [
                {
                  "name": "Text",
                  "value": "text",
                  "description": "Simple text message"
                },
                {
                  "name": "Image (Binary)",
                  "value": "imageBinary",
                  "description": "Process the binary input from the previous node"
                },
                {
                  "name": "Image (URL)",
                  "value": "imageUrl",
                  "description": "Process the image from the specified URL"
                }
              ],
              "default": "text"
            },
            {
              "displayName": "Image Data Field Name",
              "name": "binaryImageDataKey",
              "type": "string",
              "default": "data",
              "required": true,
              "description": "The name of the field in the chain's input that contains the binary image file to be processed",
              "displayOptions": {
                "show": {
                  "messageType": [
                    "imageBinary"
                  ]
                }
              }
            },
            {
              "displayName": "Image URL",
              "name": "imageUrl",
              "type": "string",
              "default": "",
              "required": true,
              "description": "URL to the image to be processed",
              "displayOptions": {
                "show": {
                  "messageType": [
                    "imageUrl"
                  ]
                }
              }
            },
            {
              "displayName": "Image Details",
              "description": "Control how the model processes the image and generates its textual understanding",
              "name": "imageDetail",
              "type": "options",
              "displayOptions": {
                "show": {
                  "type": [
                    "HumanMessagePromptTemplate"
                  ],
                  "messageType": [
                    "imageBinary",
                    "imageUrl"
                  ]
                }
              },
              "options": [
                {
                  "name": "Auto",
                  "value": "auto",
                  "description": "Model will use the auto setting which will look at the image input size and decide if it should use the low or high setting"
                },
                {
                  "name": "Low",
                  "value": "low",
                  "description": "The model will receive a low-res 512px x 512px version of the image, and represent the image with a budget of 65 tokens. This allows the API to return faster responses and consume fewer input tokens for use cases that do not require high detail."
                },
                {
                  "name": "High",
                  "value": "high",
                  "description": "Allows the model to see the low res image and then creates detailed crops of input images as 512px squares based on the input image size. Each of the detailed crops uses twice the token budget (65 tokens) for a total of 129 tokens."
                }
              ],
              "default": "auto"
            },
            {
              "displayName": "Message",
              "name": "message",
              "type": "string",
              "required": true,
              "displayOptions": {
                "hide": {
                  "messageType": [
                    "imageBinary",
                    "imageUrl"
                  ]
                }
              },
              "default": ""
            }
          ]
        }
      ],
      "typeOptions": {
        "multipleValues": true
      }
    },
    {
      "displayName": "Batch Processing",
      "name": "batching",
      "type": "collection",
      "default": {},
      "description": "Batch processing options for rate limiting",
      "options": [
        {
          "displayName": "Batch Size",
          "name": "batchSize",
          "default": 5,
          "type": "number",
          "description": "How many items to process in parallel. This is useful for rate limiting, but might impact the log output ordering."
        },
        {
          "displayName": "Delay Between Batches",
          "name": "delayBetweenBatches",
          "default": 0,
          "type": "number",
          "description": "Delay in milliseconds between batches. This is useful for rate limiting."
        }
      ],
      "displayOptions": {
        "show": {
          "@version": [
            {
              "_cnd": {
                "gte": 1.7
              }
            }
          ]
        }
      }
    },
    {
      "displayName": "Connect an <a data-action='openSelectiveNodeCreator' data-action-parameter-connectiontype='ai_outputParser'>output parser</a> on the canvas to specify the output format you require",
      "name": "notice",
      "type": "notice",
      "default": "",
      "displayOptions": {
        "show": {
          "hasOutputParser": [
            true
          ]
        }
      }
    }
  ],
  "operations": [],
  "credentials_required": [],
  "generated_at": "2025-07-23T02:24:22.245Z",
  "api_version": "1.0.0"
}