{
  "node_type": "nodes-langchain.vectorStoreInMemory",
  "package_name": "@n8n/n8n-nodes-langchain",
  "display_name": "Simple Vector Store",
  "description": "The easiest way to experiment with vector stores, without external setup.",
  "category": "transform",
  "development_style": "programmatic",
  "is_ai_tool": 0,
  "is_trigger": 0,
  "is_webhook": 0,
  "is_versioned": 1,
  "version": "1.3",
  "documentation": "---\n#https://www.notion.so/n8n/Frontmatter-432c2b8dff1f43d4b1c8d20075510fe4\ntitle: Simple Vector Store node documentation\ndescription: Learn how to use the Simple Vector Store node in n8n. Follow technical documentation to integrate Simple Vector Store node into your workflows.\ncontentType: [integration, reference]\npriority: medium\n---\n\n# Simple Vector Store node\n\nUse the Simple Vector Store node to store and retrieve [embeddings](/glossary.md#ai-embedding) in n8n's in-app memory. \n\nOn this page, you'll find the node parameters for the Simple Vector Store node, and links to more resources.\n\n--8<-- \"_snippets/integrations/builtin/cluster-nodes/sub-node-expression-resolution.md\"\n\n/// note | This node is different from AI memory nodes\nThe simple vector storage described here is different to the AI memory nodes such as [Simple Memory](/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.memorybufferwindow/index.md).\n\nThis node creates a [vector database](/glossary.md#ai-vector-store) in the app memory.\n///\n\n## Data safety limitations\n\nBefore using the Simple Vector Store node, it's important to understand its limitations and how it works.\n\n/// warning\nn8n recommends using Simple Vector store for development use only.\n///\n\n### Vector store data isn't persistent\n\nThis node stores data in memory only. All data is lost when n8n restarts and may also be purged in low-memory conditions.\n\n### All instance users can access vector store data\n\nMemory keys for the Simple Vector Store node are global, not scoped to individual workflows.\n\nThis means that all users of the instance can access vector store data by adding a Simple Vector Store node and selecting the memory key, regardless of the access controls set for the original workflow. Take care not to expose sensitive information when ingesting data with the Simple Vector Store node.\n\n## Node usage patterns\n\nYou can use the Simple Vector Store node in the following patterns.\n\n### Use as a regular node to insert and retrieve documents\n\nYou can use the Simple Vector Store as a regular node to insert or get documents. This pattern places the Simple Vector Store in the regular connection flow without using an agent.\n\nYou can see an example of in step 2 of [this template](https://n8n.io/workflows/2465-building-your-first-whatsapp-chatbot/).\n\n### Connect directly to an AI agent as a tool\n\nYou can connect the Simple Vector Store node directly to the [tool](/glossary.md#ai-tool) connector of an [AI agent](/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.agent/index.md) to use a vector store as a resource when answering queries.\n\nHere, the connection would be: AI agent (tools connector) -> Simple Vector Store node.\n\n### Use a retriever to fetch documents\n\nYou can use the [Vector Store Retriever](/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.retrievervectorstore.md) node with the Simple Vector Store node to fetch documents from the Simple Vector Store node. This is often used with the [Question and Answer Chain](/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.chainretrievalqa/index.md) node to fetch documents from the vector store that match the given chat input.\n\nAn [example of the connection flow](https://n8n.io/workflows/1960-ask-questions-about-a-pdf-using-ai/) (the linked example uses Pinecone, but the pattern is the same) would be: Question and Answer Chain (Retriever connector) -> Vector Store Retriever (Vector Store connector) -> Simple Vector Store.\n\n### Use the Vector Store Question Answer Tool to answer questions\n\nAnother pattern uses the [Vector Store Question Answer Tool](/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.toolvectorstore.md) to summarize results and answer questions from the Simple Vector Store node. Rather than connecting the Simple Vector Store directly as a tool, this pattern uses a tool specifically designed to summarizes data in the vector store.\n\nThe [connections flow](https://n8n.io/workflows/2465-building-your-first-whatsapp-chatbot/) in this case would look like this: AI agent (tools connector) -> Vector Store Question Answer Tool (Vector Store connector) -> Simple Vector store.\n\n## Memory Management\n\nThe Simple Vector Store implements memory management to prevent excessive memory usage:\n\n- Automatically cleans up old vector stores when memory pressure increases\n- Removes inactive stores that haven't been accessed for a configurable amount of time\n\n### Configuration Options\n\nYou can control memory usage with these environment variables:\n\n | Variable                      | Type   | Default | Description                                                                         |\n |-------------------------------|--------|---------|-------------------------------------------------------------------------------------|\n | `N8N_VECTOR_STORE_MAX_MEMORY` | Number | -1      | Maximum memory in MB allowed for all vector stores combined (-1 to disable limits). |\n | `N8N_VECTOR_STORE_TTL_HOURS`  | Number | -1      | Hours of inactivity after which a store gets removed (-1 to disable TTL).           |\n\nOn n8n Cloud, these values are preset to 100MB (about 8,000 documents, depending on document size and metadata) and 7 days respectively. For self-hosted instances, both values default to -1(no memory limits or time-based cleanup).\n\n## Node parameters\n\n--8<-- \"_snippets/integrations/builtin/cluster-nodes/vector-store-mode.md\"\n\n--8<-- \"_snippets/integrations/builtin/cluster-nodes/vector-store-rerank-results.md\"\n\n<!-- vale from-write-good.Weasel = NO -->\n### Get Many parameters\n<!-- vale from-write-good.Weasel = YES -->\n\n* **Memory Key**: Select or create the key containing the vector memory you want to query.\n* **Prompt**: Enter the search query.\n* **Limit**: Enter how many results to retrieve from the vector store. For example, set this to `10` to get the ten best results.\n\n\n### Insert Documents parameters\n\n* **Memory Key**: Select or create the key you want to store the vector memory as.\n* **Clear Store**: Use this parameter to control whether to wipe the vector store for the given memory key for this workflow before inserting data (turned on).\n\n### Retrieve Documents (As Vector Store for Chain/Tool) parameters\n\n* **Memory Key**: Select or create the key containing the vector memory you want to query.\n\n### Retrieve Documents (As Tool for AI Agent) parameters\n\n* **Name**: The name of the vector store.\n* **Description**: Explain to the LLM what this tool does. A good, specific description allows LLMs to produce expected results more often.\n* **Memory Key**: Select or create the key containing the vector memory you want to query.\n* **Limit**: Enter how many results to retrieve from the vector store. For example, set this to `10` to get the ten best results.\n\n## Templates and examples\n\n<!-- see https://www.notion.so/n8n/Pull-in-templates-for-the-integrations-pages-37c716837b804d30a33b47475f6e3780 -->\n[[ templatesWidget(page.title, 'in-memory-vector-store') ]]\n\n## Related resources\n\nRefer to [LangChains's Memory Vector Store documentation](https://js.langchain.com/docs/integrations/vectorstores/memory/){:target=_blank .external-link} for more information about the service.\n\n--8<-- \"_snippets/integrations/builtin/cluster-nodes/langchain-overview-link.md\"\n--8<-- \"_glossary/ai-glossary.md\"\n",
  "properties_schema": [
    {
      "displayName": "Tip: Get a feel for vector stores in n8n with our",
      "name": "ragStarterCallout",
      "type": "callout",
      "default": "",
      "typeOptions": {
        "calloutAction": {
          "label": "RAG starter template",
          "type": "openRagStarterTemplate"
        }
      }
    },
    {
      "displayName": "Operation Mode",
      "name": "mode",
      "type": "options",
      "default": "retrieve",
      "options": [
        {
          "name": "Get Many",
          "value": "load",
          "description": "Get many ranked documents from vector store for query",
          "action": "Get ranked documents from vector store"
        },
        {
          "name": "Insert Documents",
          "value": "insert",
          "description": "Insert documents into vector store",
          "action": "Add documents to vector store"
        },
        {
          "name": "Retrieve Documents (As Vector Store for Chain/Tool)",
          "value": "retrieve",
          "description": "Retrieve documents from vector store to be used as vector store with AI nodes",
          "action": "Retrieve documents for Chain/Tool as Vector Store",
          "outputConnectionType": "ai_vectorStore"
        },
        {
          "name": "Retrieve Documents (As Tool for AI Agent)",
          "value": "retrieve-as-tool",
          "description": "Retrieve documents from vector store to be used as tool with AI nodes",
          "action": "Retrieve documents for AI Agent as Tool",
          "outputConnectionType": "ai_tool"
        }
      ],
      "noDataExpression": true
    },
    {
      "displayName": "This node must be connected to a vector store retriever. <a data-action='openSelectiveNodeCreator' data-action-parameter-connectiontype='ai_retriever'>Insert one</a>",
      "name": "notice",
      "type": "notice",
      "default": "",
      "displayOptions": {
        "show": {
          "mode": [
            "retrieve"
          ]
        }
      },
      "typeOptions": {
        "containerClass": "ndv-connection-hint-notice"
      }
    },
    {
      "displayName": "Name",
      "name": "toolName",
      "type": "string",
      "default": "",
      "description": "Name of the vector store",
      "required": true,
      "displayOptions": {
        "show": {
          "@version": [
            {
              "_cnd": {
                "lte": 1.2
              }
            }
          ],
          "mode": [
            "retrieve-as-tool"
          ]
        }
      }
    },
    {
      "displayName": "Description",
      "name": "toolDescription",
      "type": "string",
      "default": "",
      "description": "Explain to the LLM what this tool does, a good, specific description would allow LLMs to produce expected results much more often",
      "required": true,
      "displayOptions": {
        "show": {
          "mode": [
            "retrieve-as-tool"
          ]
        }
      },
      "typeOptions": {
        "rows": 2
      }
    },
    {
      "displayName": "Memory Key",
      "name": "memoryKey",
      "type": "string",
      "default": "vector_store_key",
      "description": "The key to use to store the vector memory in the workflow data. The key will be prefixed with the workflow ID to avoid collisions.",
      "displayOptions": {
        "show": {
          "@version": [
            {
              "_cnd": {
                "lte": 1.1
              }
            }
          ]
        }
      }
    },
    {
      "displayName": "Memory Key",
      "name": "memoryKey",
      "type": "resourceLocator",
      "default": {
        "mode": "list",
        "value": "vector_store_key"
      },
      "description": "The key to use to store the vector memory in the workflow data. These keys are shared between workflows.",
      "required": true,
      "displayOptions": {
        "show": {
          "@version": [
            {
              "_cnd": {
                "gte": 1.2
              }
            }
          ]
        }
      }
    },
    {
      "displayName": "Embedding Batch Size",
      "name": "embeddingBatchSize",
      "type": "number",
      "default": 200,
      "description": "Number of documents to embed in a single batch",
      "displayOptions": {
        "show": {
          "mode": [
            "insert"
          ],
          "@version": [
            {
              "_cnd": {
                "gte": 1.1
              }
            }
          ]
        }
      }
    },
    {
      "displayName": "Clear Store",
      "name": "clearStore",
      "type": "boolean",
      "default": false,
      "description": "Whether to clear the store before inserting new data",
      "displayOptions": {
        "show": {
          "mode": [
            "insert"
          ]
        }
      }
    },
    {
      "displayName": "<strong>For experimental use only</strong>: Data is stored in memory and will be lost if n8n restarts. Data may also be cleared if available memory gets low, and is accessible to all users of this instance. <a href=\"https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.vectorstoreinmemory/\">More info</a>",
      "name": "notice",
      "type": "notice",
      "default": "",
      "displayOptions": {
        "show": {
          "mode": [
            "insert"
          ]
        }
      }
    },
    {
      "displayName": "Prompt",
      "name": "prompt",
      "type": "string",
      "default": "",
      "description": "Search prompt to retrieve matching documents from the vector store using similarity-based ranking",
      "required": true,
      "displayOptions": {
        "show": {
          "mode": [
            "load"
          ]
        }
      }
    },
    {
      "displayName": "Limit",
      "name": "topK",
      "type": "number",
      "default": 4,
      "description": "Number of top results to fetch from vector store",
      "displayOptions": {
        "show": {
          "mode": [
            "load",
            "retrieve-as-tool"
          ]
        }
      }
    },
    {
      "displayName": "Include Metadata",
      "name": "includeDocumentMetadata",
      "type": "boolean",
      "default": true,
      "description": "Whether or not to include document metadata",
      "displayOptions": {
        "show": {
          "mode": [
            "load",
            "retrieve-as-tool"
          ]
        }
      }
    },
    {
      "displayName": "Rerank Results",
      "name": "useReranker",
      "type": "boolean",
      "default": false,
      "description": "Whether or not to rerank results",
      "displayOptions": {
        "show": {
          "mode": [
            "load",
            "retrieve",
            "retrieve-as-tool"
          ]
        }
      }
    },
    {
      "displayName": "ID",
      "name": "id",
      "type": "string",
      "default": "",
      "description": "ID of an embedding entry",
      "required": true,
      "displayOptions": {
        "show": {
          "mode": [
            "update"
          ]
        }
      }
    },
    {
      "displayName": "<strong>For experimental use only</strong>: Data is stored in memory and will be lost if n8n restarts. Data may also be cleared if available memory gets low, and is accessible to all users of this instance. <a href=\"https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.vectorstoreinmemory/\">More info</a>",
      "name": "notice",
      "type": "notice",
      "default": "",
      "displayOptions": {
        "show": {
          "mode": [
            "load",
            "retrieve-as-tool"
          ]
        }
      }
    },
    {
      "displayName": "<strong>For experimental use only</strong>: Data is stored in memory and will be lost if n8n restarts. Data may also be cleared if available memory gets low, and is accessible to all users of this instance. <a href=\"https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.vectorstoreinmemory/\">More info</a>",
      "name": "notice",
      "type": "notice",
      "default": "",
      "displayOptions": {
        "show": {
          "mode": [
            "retrieve"
          ]
        }
      }
    }
  ],
  "operations": [],
  "credentials_required": [],
  "updated_at": "2025-07-06 13:14:51",
  "generated_at": "2025-07-23T03:58:15.685Z",
  "api_version": "1.0.0"
}