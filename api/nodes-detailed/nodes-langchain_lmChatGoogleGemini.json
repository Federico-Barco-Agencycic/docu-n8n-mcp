{
  "node_type": "nodes-langchain.lmChatGoogleGemini",
  "package_name": "@n8n/n8n-nodes-langchain",
  "display_name": "Google Gemini Chat Model",
  "description": "Chat Model Google Gemini",
  "category": "transform",
  "development_style": "programmatic",
  "is_ai_tool": 0,
  "is_trigger": 0,
  "is_webhook": 0,
  "is_versioned": 0,
  "version": "1",
  "documentation": "---\n#https://www.notion.so/n8n/Frontmatter-432c2b8dff1f43d4b1c8d20075510fe4\ntitle: Google Gemini Chat Model node documentation\ndescription: Learn how to use the Google Gemini Chat Model node in n8n. Follow technical documentation to integrate Google Gemini Chat Model node into your workflows.\ncontentType: [integration, reference]\npriority: high\n---\n\n# Google Gemini Chat Model node\n\nUse the Google Gemini Chat Model node to use Google's Gemini chat models with conversational agents.\n\nOn this page, you'll find the node parameters for the Google Gemini Chat Model node, and links to more resources.\n\n/// note | Credentials\nYou can find authentication information for this node [here](/integrations/builtin/credentials/googleai.md).\n///\n\n--8<-- \"_snippets/integrations/builtin/cluster-nodes/sub-node-expression-resolution.md\"\n\n## Node parameters\n\n* **Model**: Select the model to use to generate the completion.\n\nn8n dynamically loads models from the Google Gemini API and you'll only see the models available to your account.\n\n## Node options\n\n* **Maximum Number of Tokens**: Enter the maximum number of tokens used, which sets the completion length.\n* **Sampling Temperature**: Use this option to control the randomness of the sampling process. A higher temperature creates more diverse sampling, but increases the risk of hallucinations.\n* **Top K**: Enter the number of token choices the model uses to generate the next token.\n* **Top P**: Use this option to set the probability the completion should use. Use a lower value to ignore less probable options. \n* **Safety Settings**: Gemini supports adjustable safety settings. Refer to Google's [Gemini API safety settings](https://ai.google.dev/docs/safety_setting_gemini){:target=_blank .external-link} for information on the available filters and levels.\n\n## Templates and examples\n\n<!-- see https://www.notion.so/n8n/Pull-in-templates-for-the-integrations-pages-37c716837b804d30a33b47475f6e3780 -->\n[[ templatesWidget(page.title, 'google-gemini-chat-model') ]]\n\n## Related resources\n\nRefer to [LangChain's Google Gemini documentation](https://js.langchain.com/docs/integrations/chat/google_generativeai){:target=_blank .external-link} for more information about the service.\n\n--8<-- \"_snippets/integrations/builtin/cluster-nodes/langchain-overview-link.md\"\n--8<-- \"_glossary/ai-glossary.md\"\n",
  "properties_schema": [
    {
      "displayName": "This node must be connected to an AI chain. <a data-action='openSelectiveNodeCreator' data-action-parameter-creatorview='AI'>Insert one</a>",
      "name": "notice",
      "type": "notice",
      "default": "",
      "typeOptions": {
        "containerClass": "ndv-connection-hint-notice"
      }
    },
    {
      "displayName": "Model",
      "name": "modelName",
      "type": "options",
      "default": "models/gemini-1.0-pro",
      "description": "The model which will generate the completion. <a href=\"https://developers.generativeai.google/api/rest/generativelanguage/models/list\">Learn more</a>.",
      "typeOptions": {
        "loadOptions": {
          "routing": {
            "request": {
              "method": "GET",
              "url": "/v1beta/models"
            },
            "output": {
              "postReceive": [
                {
                  "type": "rootProperty",
                  "properties": {
                    "property": "models"
                  }
                },
                {
                  "type": "filter",
                  "properties": {
                    "pass": "={{ !$responseItem.name.includes('embedding') }}"
                  }
                },
                {
                  "type": "setKeyValue",
                  "properties": {
                    "name": "={{$responseItem.name}}",
                    "value": "={{$responseItem.name}}",
                    "description": "={{$responseItem.description}}"
                  }
                },
                {
                  "type": "sort",
                  "properties": {
                    "key": "name"
                  }
                }
              ]
            }
          }
        }
      }
    },
    {
      "displayName": "Options",
      "name": "options",
      "type": "collection",
      "default": {},
      "description": "Additional options to add",
      "options": [
        {
          "displayName": "Maximum Number of Tokens",
          "name": "maxOutputTokens",
          "default": 2048,
          "description": "The maximum number of tokens to generate in the completion",
          "type": "number"
        },
        {
          "displayName": "Sampling Temperature",
          "name": "temperature",
          "default": 0.4,
          "typeOptions": {
            "maxValue": 1,
            "minValue": 0,
            "numberPrecision": 1
          },
          "description": "Controls randomness: Lowering results in less random completions. As the temperature approaches zero, the model will become deterministic and repetitive.",
          "type": "number"
        },
        {
          "displayName": "Top K",
          "name": "topK",
          "default": 32,
          "typeOptions": {
            "maxValue": 40,
            "minValue": -1,
            "numberPrecision": 1
          },
          "description": "Used to remove \"long tail\" low probability responses. Defaults to -1, which disables it.",
          "type": "number"
        },
        {
          "displayName": "Top P",
          "name": "topP",
          "default": 1,
          "typeOptions": {
            "maxValue": 1,
            "minValue": 0,
            "numberPrecision": 1
          },
          "description": "Controls diversity via nucleus sampling: 0.5 means half of all likelihood-weighted options are considered. We generally recommend altering this or temperature but not both.",
          "type": "number"
        },
        {
          "displayName": "Safety Settings",
          "name": "safetySettings",
          "type": "fixedCollection",
          "typeOptions": {
            "multipleValues": true
          },
          "default": {
            "values": {
              "category": "HARM_CATEGORY_HARASSMENT",
              "threshold": "HARM_BLOCK_THRESHOLD_UNSPECIFIED"
            }
          },
          "placeholder": "Add Option",
          "options": [
            {
              "name": "values",
              "displayName": "Values",
              "values": [
                {
                  "displayName": "Safety Category",
                  "name": "category",
                  "type": "options",
                  "description": "The category of harmful content to block",
                  "default": "HARM_CATEGORY_UNSPECIFIED",
                  "options": [
                    {
                      "value": "HARM_CATEGORY_HARASSMENT",
                      "name": "HARM_CATEGORY_HARASSMENT",
                      "description": "Harassment content"
                    },
                    {
                      "value": "HARM_CATEGORY_HATE_SPEECH",
                      "name": "HARM_CATEGORY_HATE_SPEECH",
                      "description": "Hate speech and content"
                    },
                    {
                      "value": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
                      "name": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
                      "description": "Sexually explicit content"
                    },
                    {
                      "value": "HARM_CATEGORY_DANGEROUS_CONTENT",
                      "name": "HARM_CATEGORY_DANGEROUS_CONTENT",
                      "description": "Dangerous content"
                    }
                  ]
                },
                {
                  "displayName": "Safety Threshold",
                  "name": "threshold",
                  "type": "options",
                  "description": "The threshold of harmful content to block",
                  "default": "HARM_BLOCK_THRESHOLD_UNSPECIFIED",
                  "options": [
                    {
                      "value": "HARM_BLOCK_THRESHOLD_UNSPECIFIED",
                      "name": "HARM_BLOCK_THRESHOLD_UNSPECIFIED",
                      "description": "Threshold is unspecified"
                    },
                    {
                      "value": "BLOCK_LOW_AND_ABOVE",
                      "name": "BLOCK_LOW_AND_ABOVE",
                      "description": "Content with NEGLIGIBLE will be allowed"
                    },
                    {
                      "value": "BLOCK_MEDIUM_AND_ABOVE",
                      "name": "BLOCK_MEDIUM_AND_ABOVE",
                      "description": "Content with NEGLIGIBLE and LOW will be allowed"
                    },
                    {
                      "value": "BLOCK_ONLY_HIGH",
                      "name": "BLOCK_ONLY_HIGH",
                      "description": "Content with NEGLIGIBLE, LOW, and MEDIUM will be allowed"
                    },
                    {
                      "value": "BLOCK_NONE",
                      "name": "BLOCK_NONE",
                      "description": "All content will be allowed"
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    }
  ],
  "operations": [],
  "credentials_required": [
    {
      "name": "googlePalmApi",
      "required": true
    }
  ],
  "updated_at": "2025-07-06 13:14:51",
  "generated_at": "2025-07-23T03:58:15.685Z",
  "api_version": "1.0.0"
}