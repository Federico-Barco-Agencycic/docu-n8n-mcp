{
  "node_type": "nodes-langchain.lmChatOpenAi",
  "package_name": "@n8n/n8n-nodes-langchain",
  "display_name": "OpenAI Chat Model",
  "description": "For advanced usage with an AI chain",
  "category": "transform",
  "development_style": "programmatic",
  "is_ai_tool": 1,
  "is_trigger": 0,
  "is_webhook": 0,
  "is_versioned": 1,
  "version": "1.2",
  "documentation": "---\n#https://www.notion.so/n8n/Frontmatter-432c2b8dff1f43d4b1c8d20075510fe4\ntitle: OpenAI Chat Model node documentation\ndescription: Learn how to use the OpenAI Chat Model node in n8n. Follow technical documentation to integrate OpenAI Chat Model node into your workflows.\ncontentType: [integration, reference]\npriority: high\n---\n\n# OpenAI Chat Model node\n\nUse the OpenAI Chat Model node to use OpenAI's chat models with conversational [agents](/glossary.md#ai-agent).\n\nOn this page, you'll find the node parameters for the OpenAI Chat Model node and links to more resources.\n\n/// note | Credentials\nYou can find authentication information for this node [here](/integrations/builtin/credentials/openai.md).\n///\n\n--8<-- \"_snippets/integrations/builtin/cluster-nodes/sub-node-expression-resolution.md\"\n\n## Node parameters\n\n### Model\n\nSelect the model to use to generate the completion.\n\nn8n dynamically loads models from OpenAI and you'll only see the models available to your account.\n\n## Node options\n\nUse these options to further refine the node's behavior.\n\n### Base URL\n\nEnter a URL here to override the default URL for the API.\n\n### Frequency Penalty\n\nUse this option to control the chances of the model repeating itself. Higher values reduce the chance of the model repeating itself.\n\n### Maximum Number of Tokens\n\nEnter the maximum number of tokens used, which sets the completion length.\n\n### Response Format\n\nChoose **Text** or **JSON**. **JSON** ensures the model returns valid JSON.\n\n### Presence Penalty\n\nUse this option to control the chances of the model talking about new topics. Higher values increase the chance of the model talking about new topics.\n\n### Sampling Temperature\n\nUse this option to control the randomness of the sampling process. A higher temperature creates more diverse sampling, but increases the risk of hallucinations.\n\n### Timeout\n\nEnter the maximum request time in milliseconds.\n\n### Max Retries\n\nEnter the maximum number of times to retry a request.\n\n### Top P\n\nUse this option to set the probability the completion should use. Use a lower value to ignore less probable options. \n\n## Templates and examples\n\n<!-- see https://www.notion.so/n8n/Pull-in-templates-for-the-integrations-pages-37c716837b804d30a33b47475f6e3780 -->\n[[ templatesWidget(page.title, 'openai-chat-model') ]]\n\n## Related resources\n\nRefer to [LangChains's OpenAI documentation](https://js.langchain.com/docs/integrations/chat/openai/){:target=_blank .external-link} for more information about the service.\n\n--8<-- \"_snippets/integrations/builtin/cluster-nodes/langchain-overview-link.md\"\n\n## Common issues\n\nFor common questions or issues and suggested solutions, refer to [Common issues](/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmchatopenai/common-issues.md).\n\n--8<-- \"_glossary/ai-glossary.md\"\n",
  "properties_schema": [
    {
      "displayName": "This node must be connected to an AI chain. <a data-action='openSelectiveNodeCreator' data-action-parameter-creatorview='AI'>Insert one</a>",
      "name": "notice",
      "type": "notice",
      "default": "",
      "typeOptions": {
        "containerClass": "ndv-connection-hint-notice"
      }
    },
    {
      "displayName": "If using JSON response format, you must include word \"json\" in the prompt in your chain or agent. Also, make sure to select latest models released post November 2023.",
      "name": "notice",
      "type": "notice",
      "default": "",
      "displayOptions": {
        "show": {
          "/options.responseFormat": [
            "json_object"
          ]
        }
      }
    },
    {
      "displayName": "Model",
      "name": "model",
      "type": "options",
      "default": "gpt-4o-mini",
      "description": "The model which will generate the completion. <a href=\"https://beta.openai.com/docs/models/overview\">Learn more</a>.",
      "displayOptions": {
        "hide": {
          "@version": [
            {
              "_cnd": {
                "gte": 1.2
              }
            }
          ]
        }
      },
      "typeOptions": {
        "loadOptions": {
          "routing": {
            "request": {
              "method": "GET",
              "url": "={{ $parameter.options?.baseURL?.split(\"/\").slice(-1).pop() || $credentials?.url?.split(\"/\").slice(-1).pop() || \"v1\" }}/models"
            },
            "output": {
              "postReceive": [
                {
                  "type": "rootProperty",
                  "properties": {
                    "property": "data"
                  }
                },
                {
                  "type": "filter",
                  "properties": {
                    "pass": "={{\n\t\t\t\t\t\t\t\t\t\t\t\t($parameter.options?.baseURL && !$parameter.options?.baseURL?.startsWith('https://api.openai.com/')) ||\n\t\t\t\t\t\t\t\t\t\t\t\t($credentials?.url && !$credentials.url.startsWith('https://api.openai.com/')) ||\n\t\t\t\t\t\t\t\t\t\t\t\t$responseItem.id.startsWith('ft:') ||\n\t\t\t\t\t\t\t\t\t\t\t\t$responseItem.id.startsWith('o1') ||\n\t\t\t\t\t\t\t\t\t\t\t\t$responseItem.id.startsWith('o3') ||\n\t\t\t\t\t\t\t\t\t\t\t\t($responseItem.id.startsWith('gpt-') && !$responseItem.id.includes('instruct'))\n\t\t\t\t\t\t\t\t\t\t\t}}"
                  }
                },
                {
                  "type": "setKeyValue",
                  "properties": {
                    "name": "={{$responseItem.id}}",
                    "value": "={{$responseItem.id}}"
                  }
                },
                {
                  "type": "sort",
                  "properties": {
                    "key": "name"
                  }
                }
              ]
            }
          }
        }
      }
    },
    {
      "displayName": "Model",
      "name": "model",
      "type": "resourceLocator",
      "default": {
        "mode": "list",
        "value": "gpt-4.1-mini"
      },
      "description": "The model. Choose from the list, or specify an ID.",
      "required": true,
      "displayOptions": {
        "hide": {
          "@version": [
            {
              "_cnd": {
                "lte": 1.1
              }
            }
          ]
        }
      }
    },
    {
      "displayName": "When using non-OpenAI models via \"Base URL\" override, not all models might be chat-compatible or support other features, like tools calling or JSON response format",
      "name": "notice",
      "type": "notice",
      "default": "",
      "displayOptions": {
        "show": {
          "/options.baseURL": [
            {
              "_cnd": {
                "exists": true
              }
            }
          ]
        }
      }
    },
    {
      "displayName": "Options",
      "name": "options",
      "type": "collection",
      "default": {},
      "description": "Additional options to add",
      "options": [
        {
          "displayName": "Base URL",
          "name": "baseURL",
          "default": "https://api.openai.com/v1",
          "description": "Override the default base URL for the API",
          "type": "string",
          "displayOptions": {
            "hide": {
              "@version": [
                {
                  "_cnd": {
                    "gte": 1.1
                  }
                }
              ]
            }
          }
        },
        {
          "displayName": "Frequency Penalty",
          "name": "frequencyPenalty",
          "default": 0,
          "typeOptions": {
            "maxValue": 2,
            "minValue": -2,
            "numberPrecision": 1
          },
          "description": "Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim",
          "type": "number"
        },
        {
          "displayName": "Maximum Number of Tokens",
          "name": "maxTokens",
          "default": -1,
          "description": "The maximum number of tokens to generate in the completion. Most models have a context length of 2048 tokens (except for the newest models, which support 32,768).",
          "type": "number",
          "typeOptions": {
            "maxValue": 32768
          }
        },
        {
          "displayName": "Response Format",
          "name": "responseFormat",
          "default": "text",
          "type": "options",
          "options": [
            {
              "name": "Text",
              "value": "text",
              "description": "Regular text response"
            },
            {
              "name": "JSON",
              "value": "json_object",
              "description": "Enables JSON mode, which should guarantee the message the model generates is valid JSON"
            }
          ]
        },
        {
          "displayName": "Presence Penalty",
          "name": "presencePenalty",
          "default": 0,
          "typeOptions": {
            "maxValue": 2,
            "minValue": -2,
            "numberPrecision": 1
          },
          "description": "Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics",
          "type": "number"
        },
        {
          "displayName": "Sampling Temperature",
          "name": "temperature",
          "default": 0.7,
          "typeOptions": {
            "maxValue": 2,
            "minValue": 0,
            "numberPrecision": 1
          },
          "description": "Controls randomness: Lowering results in less random completions. As the temperature approaches zero, the model will become deterministic and repetitive.",
          "type": "number"
        },
        {
          "displayName": "Reasoning Effort",
          "name": "reasoningEffort",
          "default": "medium",
          "description": "Controls the amount of reasoning tokens to use. A value of \"low\" will favor speed and economical token usage, \"high\" will favor more complete reasoning at the cost of more tokens generated and slower responses.",
          "type": "options",
          "options": [
            {
              "name": "Low",
              "value": "low",
              "description": "Favors speed and economical token usage"
            },
            {
              "name": "Medium",
              "value": "medium",
              "description": "Balance between speed and reasoning accuracy"
            },
            {
              "name": "High",
              "value": "high",
              "description": "Favors more complete reasoning at the cost of more tokens generated and slower responses"
            }
          ],
          "displayOptions": {
            "show": {
              "/model": [
                {
                  "_cnd": {
                    "regex": "(^o1([-\\d]+)?$)|(^o[3-9].*)"
                  }
                }
              ]
            }
          }
        },
        {
          "displayName": "Timeout",
          "name": "timeout",
          "default": 60000,
          "description": "Maximum amount of time a request is allowed to take in milliseconds",
          "type": "number"
        },
        {
          "displayName": "Max Retries",
          "name": "maxRetries",
          "default": 2,
          "description": "Maximum number of retries to attempt",
          "type": "number"
        },
        {
          "displayName": "Top P",
          "name": "topP",
          "default": 1,
          "typeOptions": {
            "maxValue": 1,
            "minValue": 0,
            "numberPrecision": 1
          },
          "description": "Controls diversity via nucleus sampling: 0.5 means half of all likelihood-weighted options are considered. We generally recommend altering this or temperature but not both.",
          "type": "number"
        }
      ]
    }
  ],
  "operations": [],
  "credentials_required": [
    {
      "name": "openAiApi",
      "required": true
    }
  ],
  "updated_at": "2025-07-06 13:14:51",
  "generated_at": "2025-07-23T03:58:15.685Z",
  "api_version": "1.0.0"
}