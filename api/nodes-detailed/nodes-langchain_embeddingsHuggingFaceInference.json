{
  "node_type": "nodes-langchain.embeddingsHuggingFaceInference",
  "package_name": "@n8n/n8n-nodes-langchain",
  "display_name": "Embeddings Hugging Face Inference",
  "description": "Use HuggingFace Inference Embeddings",
  "category": "transform",
  "development_style": "programmatic",
  "is_ai_tool": 1,
  "is_trigger": 0,
  "is_webhook": 0,
  "is_versioned": 0,
  "version": "1",
  "documentation": "---\n#https://www.notion.so/n8n/Frontmatter-432c2b8dff1f43d4b1c8d20075510fe4\ntitle: Embeddings HuggingFace Inference node documentation\ndescription: Learn how to use the Embeddings HuggingFace Inference node in n8n. Follow technical documentation to integrate Embeddings HuggingFace Inference node into your workflows.\ncontentType: [integration, reference]\npriority: medium\n---\n\n# Embeddings HuggingFace Inference node\n\nUse the Embeddings HuggingFace Inference node to generate [embeddings](/glossary.md#ai-embedding) for a given text.\n\nOn this page, you'll find the node parameters for the Embeddings HuggingFace Inference, and links to more resources.\n\n/// note | Credentials\nYou can find authentication information for this node [here](/integrations/builtin/credentials/huggingface.md).\n///\n\n--8<-- \"_snippets/integrations/builtin/cluster-nodes/sub-node-expression-resolution.md\"\n\n## Node parameters\n\n* **Model**: Select the model to use to generate the embedding.\n\nRefer to the [Hugging Face models documentation](https://huggingface.co/models?other=embeddings){:target=_blank .external-link} for available models.\n\n## Node options\n\n* **Custom Inference Endpoint**: Enter the URL of your deployed model, hosted by HuggingFace. If you set this, n8n ignores the **Model Name**.\n\nRefer to [HuggingFace's guide to inference](https://huggingface.co/inference-endpoints){:target=_blank .external-link} for more information.\n\n## Templates and examples\n\n<!-- see https://www.notion.so/n8n/Pull-in-templates-for-the-integrations-pages-37c716837b804d30a33b47475f6e3780 -->\n[[ templatesWidget(page.title, 'embeddings-hugging-face-inference') ]]\n\n## Related resources\n\nRefer to [Langchain's HuggingFace Inference embeddings documentation](https://js.langchain.com/docs/integrations/text_embedding/hugging_face_inference/){:target=_blank .external-link} for more information about the service.\n\n--8<-- \"_snippets/integrations/builtin/cluster-nodes/langchain-overview-link.md\"\n--8<-- \"_glossary/ai-glossary.md\"\n",
  "properties_schema": [
    {
      "displayName": "This node must be connected to a vector store. <a data-action='openSelectiveNodeCreator' data-action-parameter-connectiontype='ai_vectorStore'>Insert one</a>",
      "name": "notice",
      "type": "notice",
      "default": "",
      "typeOptions": {
        "containerClass": "ndv-connection-hint-notice"
      }
    },
    {
      "displayName": "Each model is using different dimensional density for embeddings. Please make sure to use the same dimensionality for your vector store. The default model is using 768-dimensional embeddings.",
      "name": "notice",
      "type": "notice",
      "default": ""
    },
    {
      "displayName": "Model Name",
      "name": "modelName",
      "type": "string",
      "default": "sentence-transformers/distilbert-base-nli-mean-tokens",
      "description": "The model name to use from HuggingFace library"
    },
    {
      "displayName": "Options",
      "name": "options",
      "type": "collection",
      "default": {},
      "description": "Additional options to add",
      "options": [
        {
          "displayName": "Custom Inference Endpoint",
          "name": "endpointUrl",
          "default": "",
          "description": "Custom endpoint URL",
          "type": "string"
        }
      ]
    }
  ],
  "operations": [],
  "credentials_required": [
    {
      "name": "huggingFaceApi",
      "required": true
    }
  ],
  "updated_at": "2025-07-06 13:14:51",
  "generated_at": "2025-07-23T03:58:15.685Z",
  "api_version": "1.0.0"
}